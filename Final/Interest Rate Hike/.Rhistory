qt(0.05/2, 7)
source('~/Dropbox/Coursera/Practical Machine Learning/Project/Project.R')
install.packages("rattle")
source('~/.active-rstudio-document')
library(caret)
library(ggplot2)
library(gridExtra)
library(rpart)
library(randomForest)
library(rattle)
library(doMC)
registerDoMC(cores = 4)
# The data is imported from hard drive and into to R memory. The data can also be imported directly from the URL as well.
training <- read.csv("~/Dropbox/Coursera/Practical Machine Learning/Project/pml-training.csv")
testing <- read.csv("~/Dropbox/Coursera/Practical Machine Learning/Project/pml-testing.csv")
# Inspecting the data, several column vectors that are empty and with NA values are found. This can be dealt with by specifying na.strings during import itself.
training <- read.csv("~/Dropbox/Coursera/Practical Machine Learning/Project/pml-training.csv", na.strings = c(NA, '', '#DIV/0!'))
testing <- read.csv("~/Dropbox/Coursera/Practical Machine Learning/Project/pml-testing.csv", , na.strings = c(NA, '', '#DIV/0!'))
dim(training); dim(testing)
# Examining the data suggests there are still columns with high percentage of NA values
training <- training[ , (nrow(training) - colSums(is.na(training)))/nrow(training) > 0.9]
testing  <-  testing[ , (nrow(testing) - colSums(is.na(testing)))/nrow(testing) > 0.9]
dim(training); dim(testing)
# Plot the interactions by user, by classe.
grid_arrange_shared_legend <- function(...) {
plots <- list(...)
g <- ggplotGrob(plots[[1]] + theme(legend.position="bottom"))$grobs
legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
lheight <- sum(legend$height)
grid.arrange(
do.call(arrangeGrob, lapply(plots, function(x)
x + theme(legend.position="none"))),
legend,
ncol = 1,
heights = unit.c(unit(1, "npc") - lheight, lheight))
}
plot1 <- ggplot(data = training, aes(x = user_name, y = total_accel_belt)) + geom_point(aes(colour = classe))
plot2 <- ggplot(data = training, aes(x = user_name, y = total_accel_arm)) + geom_point(aes(colour = classe))
plot3 <- ggplot(data = training, aes(x = user_name, y = total_accel_dumbbell)) + geom_point(aes(colour = classe))
plot4 <- ggplot(data = training, aes(x = user_name, y = total_accel_forearm)) + geom_point(aes(colour = classe))
grid_arrange_shared_legend(plot1, plot2, plot3, plot4)
ggplot(data = training, aes(x = total_accel_belt, y = accel_belt_x )) + geom_point() + facet_wrap(~classe, nrow =1)
ggplot(data = training, aes(x = total_accel_forearm, y = pitch_forearm )) + geom_point() + facet_wrap(~classe, nrow =1)
ggplot(data = training, aes(x = total_accel_dumbbell, y = magnet_dumbbell_z )) + geom_point() + facet_wrap(~classe, nrow =1)
# Removing the columns that will not be used in prediction
myTraining <- training[ , 8:60]
mTesting <- testing[ , 8:60]
dim(training); dim(testing)
# Convert the response variable to a factor variable, to be predicted
training$classe <- factor(training$classe)
# Create models for prediction:
# The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable
# in the training set. You may use any of the other variables to predict with. You should create a report describing
# how you built your model, how you used cross validation, what you think the expected out of sample error is, and why
# you made the choices you did. You will also use your prediction model to predict 20 different test cases.
# caret allows us to specify a trainControl function that can be applied across all model predictions. Lets
# first define the trainControl parameter
# Lets use a 5-fold cross-validation
trnCtrl <- trainControl(method = 'cv',
number = 5,
allowParallel = TRUE,
verboseIter = TRUE)
model1 <- train(classe ~ .,
data = training,
method = 'rf',
trControl = trnCtrl)
model2 <- train(classe ~ .,
data = training,
method = 'knn',
trControl = trnCtrl)
# c("roll_belt", "pitch_belt", "yaw_belt", "gyros_belt_x", "gyros_belt_y", "gyros_belt_z", "",
#  "accel_belt_y", "accel_belt_z", "magnet_belt_x",  "magnet_belt_y", "magnet_belt_z")
#
# pml_write_files = function(x){
#   n = length(x)
#   for(i in 1:n){
#     filename = paste0("problem_id_",i,".txt")
#     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
#   }
# }
#
# x <- evaluation_data
# x <- x[feature_set[feature_set!='classe']]
# answers <- predict(rf, newdata=x)
#
# answers
#
# pml_write_files(answers)
library(ggplot2)
ggplot(data = training, aes(x = total_accel_belt, y = accel_belt_x )) + geom_point() + facet_wrap(~classe, nrow =1)
ggplot(data = myTraining, aes(x = total_accel_belt, y = accel_belt_x )) + geom_point() + facet_wrap(~classe, nrow =1)
library(ggplot)
library(ggplot2)
library(knitr)
install.packages("knitr")
qf(0.95, df1 = 19, df2 = 24)
4.405/0.643
qf(0.95, df1 = 2, df2 = 36)
19*3
117-57
60/24
19/2.5
60/21
19/2.857
library(SDSFoundations)
?data
data()
film <- data(FilmData)
str(film)
film <- FilmData
View(film)
fivenum(film$Days)
boxplot(film$Days, main = 'Days in Theaters', xlab = 'All Films', ylab = '# of days')
hist(film$Days)
boxplot(film$Days ~ film$Genre, main = "Days in Theaters", xlab = 'Genrea', ylab = '# of days')
aggregate(Days ~ Genre, data = film)
aggregate(Days ~ Genre, film)
aggregate(Days ~ Genre, film, mean)
?aggregate
aggregate(Days ~ Genre, film, sd)
daysModel <- aov(film$Days ~ film$Genre)
summary(daysModel)
TukeyHSD(daysModel)
library(MASS)
library(ISLR)
### Simple linear regression
names(Boston)
?Boston
plot(medv~lstat,Boston)
View(Boston)
fit1=lm(medv~lstat,data=Boston)
fit1
summary(fit1)
abline(fit1,col="red")
names(fit1)
confint(fit1)
predict(fit1,data.frame(lstat=c(5,10,15)),interval="confidence")
fit2=lm(medv~lstat+age,data=Boston)
summary(fit2)
fit3=lm(medv~.,Boston)
summary(fit3)
par(mfrow=c(2,2))
plot(fit3)
fit4=update(fit3,~.-age-indus)
summary(fit4)
fit5=lm(medv~lstat*age,Boston)
summary(fit5)
fit6=lm(medv~lstat +I(lstat^2),Boston); summary(fit6)
attach(Boston)
par(mfrow=c(1,1))
plot(medv~lstat)
points(lstat,fitted(fit6),col="red",pch=20)
fit7=lm(medv~poly(lstat,4))
points(lstat,fitted(fit7),col="blue",pch=20)
plot(1:20,1:20,pch=1:20,cex=2)
`###Qualitative predictors
names(Carseats)
summary(Carseats)
fit1=lm(Sales~.+Income:Advertising+Age:Price,Carseats)
summary(fit1)
contrasts(Carseats$ShelveLoc)
regplot=function(x,y){
fit=lm(y~x)
plot(x,y)
abline(fit,col="red")
}
attach(Carseats)
regplot(Price,Sales)
regplot=function(x,y,...){
fit=lm(y~x)
plot(x,y,...)
abline(fit,col="red")
}
regplot(Price,Sales,xlab="Price",ylab="Sales",col="blue",pch=20)
OCCPerf = data.frame()
OCCPerf = edit(OCCPerf, factor.mode = "numeric")
X11()
ls
ls()
library(pROC)
install.packages("pROC")
library(pROC)
titanicDF <- read.csv('http://math.ucdenver.edu/RTutorial/titanic.txt',sep='\t')
titanicDF$Title <- ifelse(grepl('Mr ',titanicDF$Name),'Mr',ifelse(grepl('Mrs ',titanicDF$Name),'Mrs',ifelse(grepl('Miss',titanicDF$Name),'Miss','Nothing')))
# load libraries
library(caret)
library(pROC)
titanicDF <- read.csv('http://math.ucdenver.edu/RTutorial/titanic.txt',sep='\t')
?ifelse
install.packages("pROC")
library(pROC)
ls()
tcltk::View(titanicDF)
c(1:6)
install.packages("mlbench")
library(mlbench)
data("Sonar")
library(dplyr)
glimpse(Sonar)
library(caret)
set.seed(998)
inTraining = createDataPartition(Sonar$Class, p = 0.75)
inTraining = createDataPartition(Sonar$Class, p = 0.75, list = FALSE)
View(inTraining)
training = Sonar[ inTraining, ]
testing  = Sonar[-inTraining, ]
fitControl = trainControl(method = "repeatedCV",
number = 10,
repeats = 10) # 10-fold CV, repeated 10 times!
fitControl
gbmFit1 = train(Class ~ ., data = training,
method = 'gbm',
trControl = fitControl,
verbose = FALSE)
gbmFit1
summary(gbmFit1)
gbmGrid = expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode = 20)
nrow(gbmGrid)
set.seed(825)
gbmGrid
gbmFit2 = train(Class ~ ., data = training,
method = 'gbm',
trControl = fitControl,
tuneGrid = gbmGrid)
summary(gbmFit2)
gbmFit2
trellis.par.set(caretTheme())
plot(gbmFit1)
plot(gbmFit2)
plot(gbmFit2, metric = "Kappa")
?predict
load("~/Dropbox/EdX/The Analytics Edge/Final/Movies/Movies.csv")
setwd("~/Dropbox/EdX/The Analytics Edge/Final/Movies")
Movies <- read.csv("Movies.csv", stringsAsFactors=FALSE)
str(Movies)
summary(Movies)
MoviesTrain = Movies[ Movies$Year < 2010, ]
MoviesTest  = Movies[!Movies$Year < 2010, ]
# Build the linear regression model
MoviesLM = lm(Worldwide ~ ., data = MoviesTrain[ , 3:ncol(MoviesTrain)])
summary(MoviesLM)
# Correlation between Worldwide and Production.Budget
cor(MoviesTrain$Worldwide, MoviesTrain$Production.Budget)
# New model with only significant predictors
MoviesLM = lm(Worldwide ~ Runtime + Crime + Horror + Animation + History +
Nominations + Production.Budget,
data = MoviesTrain[ , 3:ncol(MoviesTrain)])
summary(MoviesLM)
# Make predictions based on the linear model
MoviesPred = predict(MoviesLM, newdata = MoviesTest)
summary(MoviesPred)
plot(MoviesTest$Worldwide ~ MoviesPred)
# Sum of Squared Errors (SSE) on the test set
SSE = sum((MoviesTest$Worldwide - MoviesPred)^2)
# Total Sum of Squares (SST) on the test set (Use mean of the Worldwide on the
# training set as baseline)
SSE
SST = sum((MoviesTest$Worldwide - mean(MoviesTrain$Worldwide))^2)
SST
1 -(SSE/SST)
library(rpart)
library(rpart.plot)
library(caTools)
library(rattle)
# Add a Performance variable based on Worldwide variable
Movies$Performance = factor(ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .75), "Excellent",
ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .25), "Average","Poor")))
table(Movies$Performance)
# Remove Worldwide variable
Movies$Worldwide = NULL
# Split Training and Testing datasets. Use sample.split function on Performance
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies, spl =  TRUE)
MoviesTest  = subset(Movies, spl = FALSE)
View(MoviesTest)
View(MoviesTrain)
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies$Performance, spl =  TRUE)
MoviesTest  = subset(Movies, spl = FALSE)
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies$Performance, spl =  TRUE)
MoviesTrain = subset(Movies, spl =  TRUE)
MoviesTest  = subset(Movies, spl = FALSE)
library(rpart)
library(rpart.plot)
library(caTools)
library(rattle)
# Add a Performance variable based on Worldwide variable
Movies$Performance = factor(ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .75), "Excellent",
ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .25), "Average","Poor")))
Movies$Performance = factor(ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .75), "Excellent",
ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .25), "Average","Poor")))
table(Movies$Performance)
View(Movies)
Movies$Worldwide = NULL
# Split Training and Testing datasets. Use sample.split function on Performance
set.seed(15071)
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies, spl =  TRUE)
MoviesTest  = subset(Movies, spl = FALSE)
table(spl)
MoviesTrain = subset(Movies, TRUE)
MoviesTest  = subset(Movies, FALSE)
MoviesTrain = subset(Movies, spl == TRUE)
MoviesTest  = subset(Movies, spl == FALSE)
MoviesCART = rpart(Performance ~ .,
data = MoviesTrain[ , 3:ncol(MoviesTrain)])
summary(MoviesCART)
prp(MoviesCART)
fancyRpartPlot(MoviesCART)
MoviesCART = rpart(Performance ~ .,
data = MoviesTrain[ , 3:ncol(MoviesTrain)],
method = "class")
set.seed(15071)
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies, spl == TRUE)
MoviesTest  = subset(Movies, spl == FALSE)
# Build CART model
MoviesCART = rpart(Performance ~ .,
data = MoviesTrain[ , 3:ncol(MoviesTrain)],
method = "class")
summary(MoviesCART)
prp(MoviesCART)
fancyRpartPlot(MoviesCART)
fancyRpartPlot(MoviesCART, sub = "")
MoviesPred = predict(MoviesCART, newdata = MoviesTest, type = "class")
MoviesPred = predict(MoviesCART, newdata = MoviesTest)
table(MoviesTest$Performance)
Movies$Performance = as.factor(Movies$Performance)
Movies$Worldwide = NULL
# Split Training and Testing datasets. Use sample.split function on Performance
set.seed(15071)
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies, spl == TRUE)
MoviesTest  = subset(Movies, spl == FALSE)
# Build CART model
MoviesCART = rpart(Performance ~ .,
data = MoviesTrain[ , 3:ncol(MoviesTrain)],
method = "class")
summary(MoviesCART)
fancyRpartPlot(MoviesCART, sub = "")
MoviesPred = predict(MoviesCART, newdata = MoviesTest)
MoviesPred = predict(MoviesCART, newdata = MoviesTest[ ,3:ncol(MoviesTest)])
table(MoviesTrain$Rated)
table(MoviesTest$Rated)
MoviesTest[MoviesTest$Rated == "Approved",]
MoviesTest[35]
MoviesTest[35,]
MoviesTest[MoviesTest$Rated == "Approved",]
MoviesTest[MoviesTest$Rated == "Approved",]$Name
str(Movies)
Movies$Rated = as.factor(Movies$Rated)
str(Movies)
setwd("~/Dropbox/EdX/The Analytics Edge/Final/Movies")
Movies <- read.csv("Movies.csv", stringsAsFactors=FALSE)
str(Movies)
summary(Movies)
MoviesTrain = Movies[ Movies$Year < 2010, ]
MoviesTest  = Movies[!Movies$Year < 2010, ]
# Build the linear regression model
MoviesLM = lm(Worldwide ~ ., data = MoviesTrain[ , 3:ncol(MoviesTrain)])
summary(MoviesLM)
# Correlation between Worldwide and Production.Budget
cor(MoviesTrain$Worldwide, MoviesTrain$Production.Budget)
# New model with only significant predictors
MoviesLM = lm(Worldwide ~ Runtime + Crime + Horror + Animation + History +
Nominations + Production.Budget,
data = MoviesTrain[ , 3:ncol(MoviesTrain)])
summary(MoviesLM)
# Make predictions based on the linear model
MoviesPred = predict(MoviesLM, newdata = MoviesTest)
plot(MoviesTest$Worldwide ~ MoviesPred)
# Sum of Squared Errors (SSE) on the test set
SSE = sum((MoviesTest$Worldwide - MoviesPred)^2)
SSE
# Total Sum of Squares (SST) on the test set (Use mean of the Worldwide on the
# training set as baseline)
SST = sum((MoviesTest$Worldwide - mean(MoviesTrain$Worldwide))^2)
SST
# R-squared calculation
1 -(SSE/SST)
#_______________________________________________________________________________
# Load libraries for building CART model
library(rpart)
library(rpart.plot)
library(caTools)
library(rattle)
# Add a Performance variable based on Worldwide variable
Movies$Performance = factor(ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .75), "Excellent",
ifelse(Movies$Worldwide > quantile(Movies$Worldwide, .25), "Average",
"Poor")))
table(Movies$Performance)
Movies$Performance = as.factor(Movies$Performance)
Movies$Rated = as.factor(Movies$Rated)
# Remove Worldwide variable
Movies$Worldwide = NULL
# Split Training and Testing datasets. Use sample.split function on Performance
set.seed(15071)
spl = sample.split(Movies$Performance, SplitRatio = 0.70)
MoviesTrain = subset(Movies, spl == TRUE)
MoviesTest  = subset(Movies, spl == FALSE)
# Build CART model
MoviesCART = rpart(Performance ~ .,
data = MoviesTrain[ , 3:ncol(MoviesTrain)],
method = "class")
summary(MoviesCART)
fancyRpartPlot(MoviesCART, sub = "")
MoviesPred = predict(MoviesCART, newdata = MoviesTest[ ,3:ncol(MoviesTest)])
summary(MoviesPred)
table(MoviesPred, MoviesTest$Performance)
MoviesPred
table(MoviesTest$Performance, MoviesPred > 0.5)
MoviesPred = predict(MoviesCART, newdata = MoviesTest[ ,3:ncol(MoviesTest)],
type = "class")
summary(MoviesPred)
table(MoviesTest$Performance, MoviesPred)
(36+15+16)/nrow(MoviesTest)
(36+16+16)/nrow(MoviesTest)
MoviesPred = predict(MoviesCART,
newdata = MoviesTrain[ ,3:ncol(MoviesTest)],
type = "class")
table(MoviesTrain$Performance, MoviesPred)
(36+16+16)/nrow(MoviesTrain)
(96+41+46)/nrow(MoviesTrain)
MoviesPred = predict(MoviesCART,
newdata = MoviesTest[ ,3:ncol(MoviesTest)],
type = "class")
table(MoviesTest$Performance, MoviesPred)
(36+16+16)/nrow(MoviesTest)
table(MoviesTrain$Performance)
116/nrow(MoviesTrain)
table(MoviesTest$Performance)
50/nrow(MoviesTest)
rattle()
install.packages("cairoDevice")
library("cairoDevice", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("rggobi")
fedFunds <- read.csv("~/Dropbox/EdX/The Analytics Edge/Final/Interest Rate Hike/federalFundsRate.csv", stringsAsFactors=FALSE)
View(fedFunds)
setwd("~/Dropbox/EdX/The Analytics Edge/Final/Interest Rate Hike")
str(fedFunds)
table(fedFunds$Streak)
table(fedFunds$Streak < 0)
prop.table(table(fedFunds$Streak < 0))
prop.table(table(fedFunds$Streak > 0))
prop.table(table(fedFunds$RaisedFedFunds))
which.max(table(fedFunds$Chairman))
table(fedFunds$Chairman, fedFunds$RaisedFedFunds)
fedFunds$Chairman       = as.factor(fedFunds$Chairman)
fedFunds$DemocraticPres = as.factor(fedFunds$DemocraticPres)
fedFunds$RaisedFedFunds = as.factor(fedFunds$RaisedFedFunds)
set.seed(201)
library(caTools)
spl = sample.split(fedFunds$RaisedFedFunds, 0.7)
training = subset(fedFunds, spl == TRUE)
testing  = subset(fedFunds, spl == FALSE)
fundsGLM = glm(RaisedFedFunds ~ PreviousRate + Streak + Unemployment +
HomeownershipRate + DemocraticPres +
MonthsUntilElection,
data = training)
fundsGLM = glm(RaisedFedFunds ~ PreviousRate + Streak + Unemployment +
HomeownershipRate + DemocraticPres +
MonthsUntilElection,
data = training, family = "binomial")
summary(fundsGLM)
table(fedFunds$DemocraticPres)
testSet = data.frame(PreviousRate = 1.7, Streak = -3, Unemployment = 5.1,
HomeownershipRate = 65.3, DemocraticPres = 0,
MonthsUntilElection = 18)
testSet
predict(fundsGLM, newdata = testSet)
testSet[DemocraticPres] = 0
testSet = data.frame(PreviousRate = 1.7, Streak = -3, Unemployment = 5.1,
HomeownershipRate = 65.3, DemocraticPres = 0,
MonthsUntilElection = 18)
testSet
testSet$DemocraticPres = as.factor(testSet$DemocraticPres)
predict(fundsGLM, newdata = testSet)
e**-0.63477
exp(-0.63477)
summary(fundsGLM)
predict(fundsGLM, newdata = testSet, type = "response")
testingPred = predict(fundsGLM ,newdata = testing, type = "response")
table(testing$RaisedFedFunds, testingPred > 0.5)
(60+57)/nrow(testing)
table(testing$RaisedFedFunds)
88/(88+87)
(88 - 57) + (87 - 60)
table(testing$RaisedFedFunds, testingPred =1)
table(testing$RaisedFedFunds, testingPred >= 1)
table(testing$RaisedFedFunds, testingPred >= 0)
table(testing$RaisedFedFunds, testingPred >= 0.4)
(60+57)/nrow(testing)
table(testing$RaisedFedFunds, testingPred > 0.5)
table(testing$RaisedFedFunds)
87 - 60
table(testingPred < 0.5)
(60+57)/nrow(testing)                                    # Accuracy
predROCR = prediction(fundsGLM, testing$RaisedFedFunds)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
performance(predROCR, "auc")@y.values
library(ROCR)
predROCR = prediction(fundsGLM, testing$RaisedFedFunds)
predROCR = prediction(testingPred, testing$RaisedFedFunds)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
performance(predROCR, "auc")@y.values
plot(perfROCR)
